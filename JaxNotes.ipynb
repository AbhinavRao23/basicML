{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4eb8c7",
   "metadata": {},
   "source": [
    "# JAX Notes\n",
    "\n",
    "## Contents\n",
    "\n",
    "**1. You don't know JAX**<br>\n",
    " - Basic functionality of JAX\n",
    " - Basic Neural Net application\n",
    " \n",
    "**2. Quickstart**<br>\n",
    " - Basic functionality with little more under the hood look\n",
    " \n",
    "**3. Neural Network and Data-loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42ec7e",
   "metadata": {},
   "source": [
    "# 1. You don't know JAX\n",
    "\n",
    "https://colinraffel.com/blog/you-don-t-know-jax.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f896f757",
   "metadata": {},
   "source": [
    "Jax is numpy made to interface with specialized parallel computing hardware for ML purposes\n",
    "\n",
    "So what does it need the numpy doesn't have?<br>\n",
    "    1. JIT - Just in time compilation --> Optimized compilation to enhance speed. Makes function computation faster.<br>\n",
    "    2. Gradients - Some way to enhance methods of producing gradients of any function outputs wrt chosen params.<br>\n",
    "    3. Vectorization - Batching of inputs into function to be executed in parallel.<br>\n",
    "    \n",
    "JAX calls the above modifications to numpy as 'transformations'. They are implemented as functions, namely, jit(), grad() and vmap()/pmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00eba272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random # to generate random numbers\n",
    "import itertools # to count\n",
    "\n",
    "import jax\n",
    "import jax.numpy as np #allows previous numpy code to be directly interchanged with JAX\n",
    "import numpy as onp\n",
    "#NOTE: The convention of importing JAX is still divisive -->\n",
    "# JAX centric new codes import jax.numpy as jnp and numpy as np\n",
    "# But old codes with numpy that are now expected to work on jax just edit the numpy to jax.numpy\n",
    "# onp is for original numpy\n",
    "\n",
    "import time\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67052d1",
   "metadata": {},
   "source": [
    "Chosen example: One of the core problems of AGI is learning the Exclusive OR (XOR) function with a neural network. Based on the book Perceptron by Minsky and Papert, who claimed XOR was not solvable with 2 layer feedforward layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6564190d",
   "metadata": {},
   "source": [
    "### Net & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb4942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid nonlinearity - usual code\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Computes our network's output - w1\n",
    "def net(params, x):\n",
    "    w1, b1, w2, b2 = params #w1 - 3x2, b1 - 3x1, w2 - 3x1, b2 - 1x1\n",
    "    hidden = np.tanh(np.dot(w1, x) + b1) #output of hidden layer\n",
    "    return sigmoid(np.dot(w2, hidden) + b2) #output layer\n",
    "\n",
    "# Cross-entropy loss\n",
    "def loss(params, x, y):\n",
    "    out = net(params, x)\n",
    "    cross_entropy = -y * np.log(out) - (1 - y)*np.log(1 - out)\n",
    "    return cross_entropy\n",
    "\n",
    "# Utility function for testing whether the net produces the correct\n",
    "# output for all possible inputs\n",
    "def test_all_inputs(inputs, params):\n",
    "    predictions = [int(net(params, inp) > 0.5) for inp in inputs]\n",
    "    for inp, out in zip(inputs, predictions):\n",
    "        print(inp, '->', out)\n",
    "    return (predictions == [onp.bitwise_xor(*inp) for inp in inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f343d",
   "metadata": {},
   "source": [
    "### Training - no batches, one sample at a time, without JIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7248ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 time taken: 0.009472131729125977 s\n",
      "[0 0] -> 1\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 10 time taken: 0.005346059799194336 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n",
      "Iteration 20 time taken: 0.005450010299682617 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 30 time taken: 0.005522966384887695 s\n",
      "[0 0] -> 1\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 40 time taken: 0.0057489871978759766 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n",
      "Iteration 50 time taken: 0.0054090023040771484 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "____________________________________________________________________________________________________\n",
      "Total time taken: 0.29266786575317383 s\n"
     ]
    }
   ],
   "source": [
    "def initial_params():\n",
    "    return [\n",
    "        onp.random.randn(3, 2),  # w1\n",
    "        onp.random.randn(3),  # b1\n",
    "        onp.random.randn(3),  # w2\n",
    "        onp.random.randn(),  #b2\n",
    "    ]\n",
    "\n",
    "loss_grad = jax.grad(loss) #loss is a function, loss_grad is also a function\n",
    "\n",
    "# Stochastic gradient descent learning rate\n",
    "learning_rate = 1.\n",
    "# All possible inputs\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Initialize parameters randomly\n",
    "params = initial_params()\n",
    "\n",
    "startfull = time.time()\n",
    "for n in itertools.count(): #just counts, consider using while?\n",
    "    start = time.time()\n",
    "    # Grab a single random input, notice x is jax array\n",
    "    x = inputs[onp.random.choice(inputs.shape[0])] #randomly gives integer in range.  \n",
    "    #True stochastic gradient descent. Since only one sample per cycle\n",
    "    # Compute the target output\n",
    "    y = onp.bitwise_xor(*x)\n",
    "    \n",
    "    # Get the gradient of the loss for this input/output pair\n",
    "    grads = loss_grad(params, x, y) #autogradient for your function, but again, only one input at a time\n",
    "    # Update parameters via gradient descent\n",
    "    params = [param - learning_rate * grad\n",
    "              for param, grad in zip(params, grads)]\n",
    "    # Every 100 iterations, check whether we've solved XOR\n",
    "    if not n % 10:\n",
    "        end = time.time()\n",
    "        print('Iteration {}'.format(n),'time taken:', end-start,'s')\n",
    "        if test_all_inputs(inputs, params):\n",
    "            break\n",
    "endfull = time.time()\n",
    "print('_'*100)\n",
    "print('Total time taken:', endfull-startfull,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66caa33f",
   "metadata": {},
   "source": [
    "### Training - no batches, one sample at a time, with JIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4d0d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 time taken: 0.034810781478881836 s\n",
      "[0 0] -> 1\n",
      "[0 1] -> 1\n",
      "[1 0] -> 0\n",
      "[1 1] -> 1\n",
      "Iteration 10 time taken: 0.00014781951904296875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 0\n",
      "[1 1] -> 1\n",
      "Iteration 20 time taken: 0.0001499652862548828 s\n",
      "[0 0] -> 1\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 30 time taken: 0.0001761913299560547 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n",
      "Iteration 40 time taken: 0.0001418590545654297 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n",
      "Iteration 50 time taken: 0.0001399517059326172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 60 time taken: 0.00013780593872070312 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 70 time taken: 0.00013899803161621094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 80 time taken: 0.00013589859008789062 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 90 time taken: 0.00013113021850585938 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 100 time taken: 0.0001347064971923828 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 110 time taken: 0.00013113021850585938 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "____________________________________________________________________________________________________\n",
      "Total time taken: 0.05852389335632324 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_grad = jax.jit(jax.grad(loss))#loss is a function, loss_grad is also a function\n",
    "\n",
    "# Stochastic gradient descent learning rate\n",
    "learning_rate = 1.\n",
    "# All possible inputs\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Initialize parameters randomly\n",
    "params = initial_params()\n",
    "\n",
    "startfull = time.time()\n",
    "for n in itertools.count(): #just counts, consider using while?\n",
    "    start = time.time()\n",
    "    # Grab a single random input, notice x is jax array\n",
    "    x = inputs[onp.random.choice(inputs.shape[0])] #randomly gives integer in range.  \n",
    "    #True stochastic gradient descent. Since only one sample per cycle\n",
    "    # Compute the target output\n",
    "    y = onp.bitwise_xor(*x)\n",
    "    \n",
    "    # Get the gradient of the loss for this input/output pair\n",
    "    grads = loss_grad(params, x, y) #autogradient for your function, but again, only one input at a time\n",
    "    # Update parameters via gradient descent\n",
    "    params = [param - learning_rate * grad\n",
    "              for param, grad in zip(params, grads)]\n",
    "    # Every 100 iterations, check whether we've solved XOR\n",
    "    if not n % 10:\n",
    "        end = time.time()\n",
    "        print('Iteration {}'.format(n),'time taken:', end-start,'s')\n",
    "        if test_all_inputs(inputs, params):\n",
    "            break\n",
    "endfull = time.time()\n",
    "print('_'*100)\n",
    "print('Total time taken:', endfull-startfull,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47245570",
   "metadata": {},
   "source": [
    "### Training - batching and JIT - mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9735b55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 time taken: 0.21003389358520508 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n",
      "Iteration 10 time taken: 0.0005619525909423828 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 20 time taken: 0.0004937648773193359 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 30 time taken: 0.0005571842193603516 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 40 time taken: 0.0004856586456298828 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 50 time taken: 0.0005261898040771484 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 60 time taken: 0.0004711151123046875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 70 time taken: 0.00048804283142089844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 80 time taken: 0.00046825408935546875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 90 time taken: 0.0004642009735107422 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 100 time taken: 0.0004730224609375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 110 time taken: 0.0004878044128417969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 120 time taken: 0.0004909038543701172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 130 time taken: 0.00047278404235839844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 140 time taken: 0.00047206878662109375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 150 time taken: 0.0004711151123046875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 160 time taken: 0.00047326087951660156 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 170 time taken: 0.0004699230194091797 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 180 time taken: 0.0004649162292480469 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 190 time taken: 0.0004930496215820312 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 200 time taken: 0.0004878044128417969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 210 time taken: 0.0004596710205078125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 220 time taken: 0.0004677772521972656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 230 time taken: 0.0007128715515136719 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 240 time taken: 0.0004749298095703125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 250 time taken: 0.0005109310150146484 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 260 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 270 time taken: 0.0005030632019042969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 280 time taken: 0.0004858970642089844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 290 time taken: 0.0005660057067871094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 300 time taken: 0.0006291866302490234 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 310 time taken: 0.00045680999755859375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 320 time taken: 0.00045490264892578125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 330 time taken: 0.0005071163177490234 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 340 time taken: 0.00047278404235839844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 350 time taken: 0.0004878044128417969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 360 time taken: 0.00047278404235839844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 370 time taken: 0.0004928112030029297 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 380 time taken: 0.0004978179931640625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 390 time taken: 0.00046896934509277344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 400 time taken: 0.0004611015319824219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 410 time taken: 0.00046825408935546875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 420 time taken: 0.00047588348388671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 430 time taken: 0.0004837512969970703 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 440 time taken: 0.0004737377166748047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 450 time taken: 0.0004608631134033203 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 460 time taken: 0.0004911422729492188 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 470 time taken: 0.0004889965057373047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 480 time taken: 0.0005090236663818359 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 490 time taken: 0.0004611015319824219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 500 time taken: 0.00044608116149902344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 510 time taken: 0.0004718303680419922 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 520 time taken: 0.0005371570587158203 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 530 time taken: 0.0004527568817138672 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 540 time taken: 0.0005230903625488281 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 550 time taken: 0.0004878044128417969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 560 time taken: 0.0004737377166748047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 570 time taken: 0.0004658699035644531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 580 time taken: 0.0004839897155761719 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 590 time taken: 0.0004649162292480469 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 600 time taken: 0.0004646778106689453 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 610 time taken: 0.0005629062652587891 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 620 time taken: 0.0004889965057373047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 630 time taken: 0.0005087852478027344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 640 time taken: 0.0004899501800537109 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 650 time taken: 0.00047087669372558594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 660 time taken: 0.00045990943908691406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 670 time taken: 0.0004851818084716797 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 680 time taken: 0.00048422813415527344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 690 time taken: 0.00048422813415527344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 700 time taken: 0.0005922317504882812 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 710 time taken: 0.00047516822814941406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 720 time taken: 0.0004918575286865234 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 730 time taken: 0.0004951953887939453 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 740 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 750 time taken: 0.0004849433898925781 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 760 time taken: 0.0004742145538330078 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 770 time taken: 0.00047516822814941406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 780 time taken: 0.0005428791046142578 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 790 time taken: 0.0004820823669433594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 800 time taken: 0.0004630088806152344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 810 time taken: 0.0005269050598144531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 820 time taken: 0.0004773139953613281 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 830 time taken: 0.0004987716674804688 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 840 time taken: 0.00047397613525390625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 850 time taken: 0.0005228519439697266 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 860 time taken: 0.00047588348388671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 870 time taken: 0.0004930496215820312 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 880 time taken: 0.00047516822814941406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 890 time taken: 0.0004942417144775391 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 900 time taken: 0.0004849433898925781 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 910 time taken: 0.0004830360412597656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 920 time taken: 0.0005190372467041016 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 930 time taken: 0.0004863739013671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 940 time taken: 0.00047588348388671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 950 time taken: 0.0005538463592529297 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 960 time taken: 0.00048470497131347656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 970 time taken: 0.0005581378936767578 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 980 time taken: 0.0005159378051757812 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 990 time taken: 0.0004918575286865234 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1000 time taken: 0.0004668235778808594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1010 time taken: 0.0004839897155761719 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1020 time taken: 0.0005440711975097656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1030 time taken: 0.00046062469482421875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1040 time taken: 0.00047016143798828125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1050 time taken: 0.0004661083221435547 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1060 time taken: 0.00046181678771972656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1070 time taken: 0.0004761219024658203 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1080 time taken: 0.0006000995635986328 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1090 time taken: 0.0005040168762207031 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1100 time taken: 0.0004978179931640625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1110 time taken: 0.0004878044128417969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1120 time taken: 0.0004830360412597656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1130 time taken: 0.0004868507385253906 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1140 time taken: 0.0004489421844482422 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1150 time taken: 0.0004589557647705078 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1160 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1170 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1180 time taken: 0.0004680156707763672 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1190 time taken: 0.0005419254302978516 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1200 time taken: 0.0004680156707763672 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1210 time taken: 0.0004909038543701172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1220 time taken: 0.0005249977111816406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1230 time taken: 0.0004799365997314453 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1240 time taken: 0.0004668235778808594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1250 time taken: 0.0004818439483642578 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1260 time taken: 0.0004520416259765625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1270 time taken: 0.0004611015319824219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1280 time taken: 0.0004658699035644531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1290 time taken: 0.0005550384521484375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1300 time taken: 0.0004892349243164062 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1310 time taken: 0.0009877681732177734 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1320 time taken: 0.00045490264892578125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1330 time taken: 0.0005350112915039062 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1340 time taken: 0.0005459785461425781 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1350 time taken: 0.0004711151123046875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1360 time taken: 0.0004620552062988281 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1370 time taken: 0.0004820823669433594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1380 time taken: 0.0004658699035644531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1390 time taken: 0.0004642009735107422 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1400 time taken: 0.00046706199645996094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1410 time taken: 0.0004949569702148438 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1420 time taken: 0.0005791187286376953 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1430 time taken: 0.00047588348388671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1440 time taken: 0.00045800209045410156 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1450 time taken: 0.0004611015319824219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1460 time taken: 0.00048422813415527344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1470 time taken: 0.0004849433898925781 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1480 time taken: 0.0004889965057373047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1490 time taken: 0.0004737377166748047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1500 time taken: 0.0004601478576660156 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1510 time taken: 0.0004680156707763672 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1520 time taken: 0.0004899501800537109 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1530 time taken: 0.0005209445953369141 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1540 time taken: 0.0005049705505371094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1550 time taken: 0.0005269050598144531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1560 time taken: 0.0005259513854980469 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1570 time taken: 0.00047087669372558594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1580 time taken: 0.0005059242248535156 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1590 time taken: 0.0004918575286865234 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1600 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1610 time taken: 0.0005500316619873047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1620 time taken: 0.0004911422729492188 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1630 time taken: 0.00047206878662109375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1640 time taken: 0.0005249977111816406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1650 time taken: 0.0005540847778320312 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1660 time taken: 0.00047278404235839844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1670 time taken: 0.0004968643188476562 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1680 time taken: 0.00047397613525390625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1690 time taken: 0.0005009174346923828 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1700 time taken: 0.0005049705505371094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1710 time taken: 0.0005121231079101562 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1720 time taken: 0.0004940032958984375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1730 time taken: 0.0005869865417480469 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1740 time taken: 0.000469207763671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1750 time taken: 0.0005109310150146484 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1760 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1770 time taken: 0.000514984130859375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1780 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1790 time taken: 0.0004892349243164062 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1800 time taken: 0.0004730224609375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1810 time taken: 0.000492095947265625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1820 time taken: 0.0004837512969970703 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1830 time taken: 0.00046896934509277344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1840 time taken: 0.0005340576171875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1850 time taken: 0.0004851818084716797 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1860 time taken: 0.0005190372467041016 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1870 time taken: 0.00048089027404785156 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1880 time taken: 0.0005221366882324219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1890 time taken: 0.0004699230194091797 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1900 time taken: 0.0005061626434326172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1910 time taken: 0.0004909038543701172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1920 time taken: 0.00048422813415527344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 1930 time taken: 0.0005049705505371094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1940 time taken: 0.0004749298095703125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1950 time taken: 0.0005366802215576172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1960 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1970 time taken: 0.0005018711090087891 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1980 time taken: 0.0004680156707763672 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 1990 time taken: 0.0004749298095703125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2000 time taken: 0.0004837512969970703 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2010 time taken: 0.0006012916564941406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2020 time taken: 0.0005970001220703125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2030 time taken: 0.0005040168762207031 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2040 time taken: 0.0008246898651123047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2050 time taken: 0.0005061626434326172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2060 time taken: 0.0005357265472412109 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2070 time taken: 0.0004909038543701172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2080 time taken: 0.0004849433898925781 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2090 time taken: 0.0005140304565429688 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2100 time taken: 0.0004928112030029297 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2110 time taken: 0.0004711151123046875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2120 time taken: 0.0005099773406982422 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2130 time taken: 0.00047588348388671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2140 time taken: 0.0004711151123046875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2150 time taken: 0.0005030632019042969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2160 time taken: 0.0005679130554199219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2170 time taken: 0.0004749298095703125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2180 time taken: 0.0005278587341308594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2190 time taken: 0.0004909038543701172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2200 time taken: 0.0005109310150146484 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2210 time taken: 0.0004830360412597656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2220 time taken: 0.0005202293395996094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2230 time taken: 0.0004761219024658203 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2240 time taken: 0.0005698204040527344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2250 time taken: 0.0005629062652587891 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2260 time taken: 0.0004849433898925781 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2270 time taken: 0.0005130767822265625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2280 time taken: 0.00048089027404785156 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2290 time taken: 0.00048279762268066406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2300 time taken: 0.0004889965057373047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2310 time taken: 0.00047588348388671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2320 time taken: 0.0004658699035644531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2330 time taken: 0.00046706199645996094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2340 time taken: 0.00046896934509277344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2350 time taken: 0.0004680156707763672 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2360 time taken: 0.00047707557678222656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2370 time taken: 0.0005400180816650391 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2380 time taken: 0.0004749298095703125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2390 time taken: 0.00047707557678222656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2400 time taken: 0.0005612373352050781 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2410 time taken: 0.0006010532379150391 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2420 time taken: 0.0005087852478027344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2430 time taken: 0.0004699230194091797 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2440 time taken: 0.0005288124084472656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2450 time taken: 0.00047397613525390625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2460 time taken: 0.00047087669372558594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2470 time taken: 0.0005750656127929688 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2480 time taken: 0.0005238056182861328 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2490 time taken: 0.0005218982696533203 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2500 time taken: 0.0005061626434326172 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2510 time taken: 0.00048804283142089844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2520 time taken: 0.0004837512969970703 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2530 time taken: 0.0004999637603759766 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2540 time taken: 0.000537872314453125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2550 time taken: 0.0004677772521972656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2560 time taken: 0.0004928112030029297 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2570 time taken: 0.0005078315734863281 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2580 time taken: 0.000514984130859375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2590 time taken: 0.00047898292541503906 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2600 time taken: 0.000492095947265625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2610 time taken: 0.00047707557678222656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2620 time taken: 0.0004999637603759766 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2630 time taken: 0.000492095947265625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2640 time taken: 0.0004851818084716797 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2650 time taken: 0.0004851818084716797 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2660 time taken: 0.0004718303680419922 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2670 time taken: 0.00045228004455566406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2680 time taken: 0.0004858970642089844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2690 time taken: 0.0004711151123046875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2700 time taken: 0.0004706382751464844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2710 time taken: 0.0004820823669433594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2720 time taken: 0.00047278404235839844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2730 time taken: 0.00047206878662109375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2740 time taken: 0.0005130767822265625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2750 time taken: 0.0004892349243164062 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2760 time taken: 0.0005388259887695312 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2770 time taken: 0.00046896934509277344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2780 time taken: 0.0005438327789306641 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2790 time taken: 0.0004837512969970703 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2800 time taken: 0.0004930496215820312 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2810 time taken: 0.0004661083221435547 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2820 time taken: 0.0005319118499755859 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2830 time taken: 0.0004830360412597656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2840 time taken: 0.000476837158203125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2850 time taken: 0.0004639625549316406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2860 time taken: 0.0004928112030029297 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2870 time taken: 0.0005309581756591797 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2880 time taken: 0.0004999637603759766 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2890 time taken: 0.0005319118499755859 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2900 time taken: 0.00047516822814941406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2910 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2920 time taken: 0.0004811286926269531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2930 time taken: 0.0004711151123046875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2940 time taken: 0.0005719661712646484 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2950 time taken: 0.0004978179931640625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2960 time taken: 0.0005991458892822266 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2970 time taken: 0.0005030632019042969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 2980 time taken: 0.0005319118499755859 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 2990 time taken: 0.0005331039428710938 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3000 time taken: 0.0004878044128417969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3010 time taken: 0.000621795654296875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3020 time taken: 0.00047516822814941406 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3030 time taken: 0.0004887580871582031 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3040 time taken: 0.0004780292510986328 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3050 time taken: 0.0004858970642089844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3060 time taken: 0.000469207763671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3070 time taken: 0.0004839897155761719 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3080 time taken: 0.0006439685821533203 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3090 time taken: 0.0004858970642089844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3100 time taken: 0.0005199909210205078 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3110 time taken: 0.0005352497100830078 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3120 time taken: 0.0005400180816650391 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3130 time taken: 0.00048804283142089844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3140 time taken: 0.0004849433898925781 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3150 time taken: 0.0004870891571044922 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3160 time taken: 0.0004830360412597656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3170 time taken: 0.0005040168762207031 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3180 time taken: 0.0004799365997314453 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3190 time taken: 0.0006096363067626953 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3200 time taken: 0.0005280971527099609 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3210 time taken: 0.0004930496215820312 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3220 time taken: 0.00047707557678222656 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3230 time taken: 0.0004868507385253906 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3240 time taken: 0.0004887580871582031 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3250 time taken: 0.0004942417144775391 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3260 time taken: 0.00046706199645996094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3270 time taken: 0.000476837158203125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3280 time taken: 0.00047898292541503906 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3290 time taken: 0.0005886554718017578 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3300 time taken: 0.00047206878662109375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3310 time taken: 0.0006809234619140625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3320 time taken: 0.0004858970642089844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3330 time taken: 0.0005471706390380859 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3340 time taken: 0.0005090236663818359 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3350 time taken: 0.0004870891571044922 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3360 time taken: 0.0005202293395996094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3370 time taken: 0.0004780292510986328 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3380 time taken: 0.0005190372467041016 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3390 time taken: 0.0005488395690917969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3400 time taken: 0.00048828125 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3410 time taken: 0.00048089027404785156 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3420 time taken: 0.0005228519439697266 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3430 time taken: 0.0005140304565429688 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3440 time taken: 0.0005168914794921875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3450 time taken: 0.0005221366882324219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3460 time taken: 0.0006592273712158203 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3470 time taken: 0.0005197525024414062 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3480 time taken: 0.00047898292541503906 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3490 time taken: 0.0004820823669433594 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3500 time taken: 0.0005252361297607422 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3510 time taken: 0.0005550384521484375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3520 time taken: 0.0005168914794921875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3530 time taken: 0.0005202293395996094 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3540 time taken: 0.0005640983581542969 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3550 time taken: 0.0005340576171875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3560 time taken: 0.0005121231079101562 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3570 time taken: 0.0005221366882324219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3580 time taken: 0.0005238056182861328 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3590 time taken: 0.0005269050598144531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3600 time taken: 0.0005190372467041016 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3610 time taken: 0.00046896934509277344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3620 time taken: 0.0005099773406982422 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3630 time taken: 0.0005090236663818359 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3640 time taken: 0.0005092620849609375 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3650 time taken: 0.0005199909210205078 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3660 time taken: 0.0005087852478027344 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3670 time taken: 0.0004718303680419922 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3680 time taken: 0.0005252361297607422 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3690 time taken: 0.0005068778991699219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3700 time taken: 0.00047326087951660156 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3710 time taken: 0.0005221366882324219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3720 time taken: 0.0004658699035644531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3730 time taken: 0.0005114078521728516 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3740 time taken: 0.0004858970642089844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3750 time taken: 0.0005118846893310547 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3760 time taken: 0.000469207763671875 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3770 time taken: 0.0005130767822265625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3780 time taken: 0.0005128383636474609 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3790 time taken: 0.0005011558532714844 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3800 time taken: 0.0004889965057373047 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3810 time taken: 0.0005218982696533203 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3820 time taken: 0.0005099773406982422 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3830 time taken: 0.0005230903625488281 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3840 time taken: 0.0004658699035644531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3850 time taken: 0.0004932880401611328 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3860 time taken: 0.0005130767822265625 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3870 time taken: 0.0005166530609130859 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3880 time taken: 0.0005879402160644531 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3890 time taken: 0.0005471706390380859 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3900 time taken: 0.0005178451538085938 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3910 time taken: 0.0005257129669189453 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3920 time taken: 0.0005209445953369141 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3930 time taken: 0.0004699230194091797 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3940 time taken: 0.0004911422729492188 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3950 time taken: 0.0005109310150146484 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 3960 time taken: 0.0005068778991699219 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3970 time taken: 0.0005991458892822266 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3980 time taken: 0.0004799365997314453 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 0\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "Iteration 3990 time taken: 0.0005259513854980469 s\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n",
      "____________________________________________________________________________________________________\n",
      "Total time taken: 2.5748400688171387 s\n"
     ]
    }
   ],
   "source": [
    "loss_grad = jax.jit(jax.vmap(jax.grad(loss), in_axes=(None, 0, 0), out_axes=0))\n",
    "# --------Just in time--parallel----batching over?-params, x[0], y[0]---O[0] --> 0th axis batching\n",
    "params = initial_params()\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "startfull = time.time()\n",
    "for n in itertools.count():\n",
    "    start = time.time()\n",
    "    \n",
    "    # Generate a batch of inputs\n",
    "    x = inputs[onp.random.choice(inputs.shape[0], size=batch_size)] #(batch_size (parallelization along here), feature_length) = (100,2)\n",
    "    y = onp.bitwise_xor(x[:, 0], x[:, 1]) #only one axis\n",
    "    \n",
    "    # The call to loss_grad remains the same!\n",
    "    grads = loss_grad(params, x, y)\n",
    "    \n",
    "    # Note that we now need to average gradients over the batch\n",
    "    params = [param - learning_rate * np.mean(grad, axis=0)\n",
    "              for param, grad in zip(params, grads)] #only difference is mean gradient for mini-batch\n",
    "    if not n % 10:\n",
    "        end = time.time()\n",
    "        print('Iteration {}'.format(n),'time taken:', end-start,'s')\n",
    "        if test_all_inputs(inputs, params):\n",
    "            break\n",
    "endfull = time.time()\n",
    "print('_'*100)\n",
    "print('Total time taken:', endfull-startfull,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2683b374",
   "metadata": {},
   "source": [
    "Batching allows more stable learning, lesser chance of divergence or incorrect minima. As seen, vectorization did not increase the per iteration time much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f500d9",
   "metadata": {},
   "source": [
    "# 2. Quickstart\n",
    "\n",
    "https://jax.readthedocs.io/en/latest/notebooks/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff0a35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp #another convention, if making jax based codebase firsthand\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ec2b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3721109   0.26423115 -0.18252768 -0.7368197  -0.44030377 -0.1521442\n",
      " -0.67135346 -0.5908641   0.73168886  0.5673026 ]\n"
     ]
    }
   ],
   "source": [
    "#creating random numbers\n",
    "#one of the few things where jax and numpy defer in syntax\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "x = random.normal(key, (10,))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "345cfd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.3 µs ± 363 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "size = 30\n",
    "x = random.normal(key, (size, size), dtype=jnp.float32)\n",
    "%timeit jnp.dot(x, x.T).block_until_ready()  # runs on the GPU\n",
    "\n",
    "#We added that block_until_ready because JAX uses asynchronous execution by default (see {ref}async-dispatch)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77259d41",
   "metadata": {},
   "source": [
    "**Asynchronous Dispatch**\n",
    "\n",
    "When an operation such as `jnp.dot(x, x)` is executed, JAX does not wait for the operation to complete before returning control to the Python program. Instead, JAX returns a `DeviceArray` value, which is a future, i.e., a value that will be produced in the future on an accelerator device but isn’t necessarily available immediately. We can inspect the `shape` or `type` of a DeviceArray without waiting for the computation that produced it to complete, and we can even pass it to another JAX computation, as we do with the addition operation here. Only if we actually inspect the value of the array from the host, for example by printing it or by converting it into a plain old `numpy.ndarray` will JAX force the Python code to wait for the computation to complete.\n",
    "\n",
    "This is called asynchronous dispatch. \n",
    "\n",
    "Why is it useful?<br>\n",
    "It allows the program to run ahead of an accelerator device, \"in the case where the host program does not actually need to inspect the output of the specific accelerator computation\". This allows the program enqueue arbitrary amounts of work on the accelerator and make more efficient use of its time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb150d",
   "metadata": {},
   "source": [
    "**NOTE: The below exercise will only make sense with a GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d3484b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.1 ms, sys: 1.73 ms, total: 42.8 ms\n",
      "Wall time: 14.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[255.01973, 246.64864, 254.13373, ..., 233.67952, 247.68939,\n",
       "        238.36853],\n",
       "       [262.65982, 253.28915, 259.18246, ..., 239.03183, 253.16756,\n",
       "        249.44124],\n",
       "       [259.38916, 252.72754, 258.2306 , ..., 237.83559, 252.41093,\n",
       "        246.62468],\n",
       "       ...,\n",
       "       [256.1581 , 250.092  , 254.72174, ..., 239.23874, 247.72684,\n",
       "        244.16638],\n",
       "       [268.22662, 258.91205, 262.33398, ..., 245.26648, 259.0539 ,\n",
       "        258.337  ],\n",
       "       [254.16138, 251.7543 , 256.083  , ..., 238.59848, 245.62595,\n",
       "        240.22354]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random.uniform(random.PRNGKey(0), (1000, 1000))\n",
    "%time jnp.dot(x, x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd9762",
   "metadata": {},
   "source": [
    "Wall time is surprisingly low, because the time was estimated not for the computation but estimated for the dispatch to accelerator. To check actual time, perform a inspection level task (convert to numpy array) or `block_until_ready()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c49b0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.8 ms, sys: 2.66 ms, total: 42.5 ms\n",
      "Wall time: 7.58 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[255.01973, 246.64864, 254.13373, ..., 233.67952, 247.68939,\n",
       "        238.36853],\n",
       "       [262.65982, 253.28915, 259.18246, ..., 239.03183, 253.16756,\n",
       "        249.44124],\n",
       "       [259.38916, 252.72754, 258.2306 , ..., 237.83559, 252.41093,\n",
       "        246.62468],\n",
       "       ...,\n",
       "       [256.1581 , 250.092  , 254.72174, ..., 239.23874, 247.72684,\n",
       "        244.16638],\n",
       "       [268.22662, 258.91205, 262.33398, ..., 245.26648, 259.0539 ,\n",
       "        258.337  ],\n",
       "       [254.16138, 251.7543 , 256.083  , ..., 238.59848, 245.62595,\n",
       "        240.22354]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time jnp.dot(x, x).block_until_ready() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daa54d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.7 µs ± 265 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from jax import device_put\n",
    "import numpy as np\n",
    "x = np.random.normal(size=(size, size)).astype(np.float32)\n",
    "x = device_put(x)\n",
    "%timeit jnp.dot(x, x.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a25a88",
   "metadata": {},
   "source": [
    "The output of `jax.device_put` still acts like an NDArray, but it only copies values back to the CPU when they're needed for printing, plotting, saving to disk, branching, etc. The behavior of `jax.device_put` is equivalent to the function `jit(lambda x: x)`, but it's faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04064fd",
   "metadata": {},
   "source": [
    "**1. Using `jax.jit` to speed up functions**\n",
    "\n",
    "JAX runs transparently on the GPU or TPU (falling back to CPU if you don't have one). However, in the above example, JAX is dispatching kernels to the GPU one operation at a time. If we have a sequence of operations, we can use the `@jit` decorator to compile multiple operations together using [XLA](https://www.tensorflow.org/xla). Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f892353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11 ms ± 153 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "    return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)\n",
    "\n",
    "x = random.normal(key, (1000000,))\n",
    "%timeit selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "485a0931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565 µs ± 47.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "selu_jit = jit(selu)\n",
    "%timeit selu_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a975445",
   "metadata": {},
   "source": [
    "This means the first time selu is called, it will be jit compiled and then cached for other use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a41816",
   "metadata": {},
   "source": [
    "**2. Using `jax.grad` for taking derivatives**\n",
    "\n",
    "Unlike pytorch, jax is more functional in its approach to gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e6ebff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25       0.19661197 0.10499357]\n"
     ]
    }
   ],
   "source": [
    "def sum_logistic(x):\n",
    "    return jnp.sum(1.0 / (1.0 + jnp.exp(-x)))\n",
    "\n",
    "x_small = jnp.arange(3.)\n",
    "derivative_fn = grad(sum_logistic)\n",
    "print(derivative_fn(x_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7adef926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25       0.19661196 0.10499357]\n"
     ]
    }
   ],
   "source": [
    "# to verify\n",
    "def derivative_sum_log(x):\n",
    "    return jnp.exp(-x)/ (1.0 + jnp.exp(-x))**2\n",
    "print(derivative_sum_log(x_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4157919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0353256\n"
     ]
    }
   ],
   "source": [
    "print(grad(jit(grad(jit(grad(sum_logistic)))))(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b909f6e",
   "metadata": {},
   "source": [
    "For more advanced autodiff, you can use `jax.vjp` for reverse-mode vector-Jacobian products and `jax.jvp` for forward-mode Jacobian-vector products. The two can be composed arbitrarily with one another, and with other JAX transformations. Here's one way to compose them to make a function that efficiently computes full Hessian matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72c75668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jacfwd, jacrev\n",
    "def hessian(fun):\n",
    "    return jit(jacfwd(jacrev(fun)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c49e01",
   "metadata": {},
   "source": [
    "**3. Auto-vectorization with `jax.vmap`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ea388",
   "metadata": {},
   "source": [
    "`~jax.vmap` is the vectorizing map. It has the familiar semantics of mapping a function along array axes, but instead of keeping the loop on the outside, it pushes the loop down into a function’s primitive operations for better performance. When composed with {func}`~jax.jit`, it can be just as fast as adding the batch dimensions by hand.\n",
    "\n",
    "This means that instead of just applying `func(var) for var in mapped(vars)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "207c1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = random.normal(key, (150, 100))\n",
    "batched_x = random.normal(key, (10, 100))\n",
    "\n",
    "def apply_matrix(v):\n",
    "    return jnp.dot(mat, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f294c",
   "metadata": {},
   "source": [
    "How would you apply the `apply_matrix` function to each of the 10 vectors in batched_x?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0b7ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naively batched\n",
      "466 µs ± 6.94 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def naively_batched_apply_matrix(v_batched):\n",
    "    return jnp.stack([apply_matrix(v) for v in v_batched])\n",
    "\n",
    "print('Naively batched')\n",
    "%timeit naively_batched_apply_matrix(batched_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7db254ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-vectorized with vmap\n",
      "18.4 µs ± 160 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def vmap_batched_apply_matrix(v_batched):\n",
    "    return vmap(apply_matrix)(v_batched)\n",
    "\n",
    "print('Auto-vectorized with vmap')\n",
    "%timeit vmap_batched_apply_matrix(batched_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75ef2e",
   "metadata": {},
   "source": [
    "# 3. Neural Networks and Data-loading\n",
    "\n",
    "https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/neural_network_with_tfds_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fcb9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0989e",
   "metadata": {},
   "source": [
    "Important to note that any library that works with numpy to make networks can be used, but in this notebook things are kept simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "163b0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "\n",
    "\n",
    "def random_layer_params(m: 'inputdim', \n",
    "                        n: 'outputdim', \n",
    "                        key, scale=1e-2): #scale being used as standard deviation to scale std normal\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "\n",
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "# Waav\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "\n",
    "layer_sizes = [784, 512, 512, 10]\n",
    "step_size = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "n_targets = 10\n",
    "params = init_network_params(layer_sizes, random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb9b7bc",
   "metadata": {},
   "source": [
    "The purpose of `random.split` is to allow you to generate an arbitrary number of independent pseudorandom values given a single key. You can certainly directly create as many random keys as you wish, but requiring this in every case would be problematic.\n",
    "\n",
    "As an example, consider an iterative solver that creates a new random vector each iteration. If keys had to be constructed manually, the user would have to pass-in an arbitrarily large number of random keys to the solver. With `random.split`, passing a single key is sufficient, and the function can split it as needed to generate as many independent pseudorandom values as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f92a6",
   "metadata": {},
   "source": [
    "**Auto-batching predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96bcc6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "# a function writtine considering\n",
    "# only one image at a time \n",
    "def predict(params, image):\n",
    "    # per-example predictions\n",
    "    activations = image\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = jnp.dot(w, activations) + b\n",
    "        activations = relu(outputs)\n",
    "\n",
    "    final_w, final_b = params[-1]\n",
    "    logits = jnp.dot(final_w, activations) + final_b\n",
    "    return logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3aac82a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# This works on single examples\n",
    "random_flattened_image = random.normal(random.PRNGKey(1), (28 * 28,))\n",
    "preds = predict(params, random_flattened_image)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c373ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid shapes!\n"
     ]
    }
   ],
   "source": [
    "# Doesn't work with a batch\n",
    "random_flattened_images = random.normal(random.PRNGKey(1), (10, 28 * 28)) # 10 images at once\n",
    "try:\n",
    "    preds = predict(params, random_flattened_images)\n",
    "except TypeError:\n",
    "    print('Invalid shapes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f3f1998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "# Let's upgrade it to handle batches using `vmap`\n",
    "\n",
    "# Make a batched version of the `predict` function\n",
    "batched_predict = vmap(predict, in_axes=(None, 0)) # we want the first dim to be parallelized (784)\n",
    "\n",
    "\n",
    "# `batched_predict` has the same call signature as `predict`\n",
    "batched_preds = batched_predict(params, random_flattened_images)\n",
    "print(batched_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "522ae6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "  \n",
    "def accuracy(params, images, targets):\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "def loss(params, images, targets):\n",
    "    preds = batched_predict(params, images)\n",
    "    return -jnp.mean(preds * targets)\n",
    "\n",
    "@jit\n",
    "def update(params, x, y):\n",
    "    grads = grad(loss)(params, x, y)\n",
    "    return [(w - step_size * dw, b - step_size * db)\n",
    "          for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c55f2055",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import tensorflow as tf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Ensure TF does not see GPU and grab all GPU memory.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# tf.config.set_visible_devices([], device_type='GPU')\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "# tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ff52aa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/abhinavrao/Abhinav/lie/tfdata/tfds\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Fetch full datasets for evaluation\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# You can convert them to NumPy arrays (or iterables of NumPy arrays) with tfds.dataset_as_numpy\u001b[39;00m\n\u001b[1;32m      6\u001b[0m mnist_data, info \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, data_dir\u001b[38;5;241m=\u001b[39mdata_dir, with_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/abhinavrao/Abhinav/lie/tfdata/tfds'\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Fetch full datasets for evaluation\n",
    "# tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)\n",
    "# You can convert them to NumPy arrays (or iterables of NumPy arrays) with tfds.dataset_as_numpy\n",
    "mnist_data, info = tfds.load(name=\"mnist\", batch_size=-1, data_dir=data_dir, with_info=True)\n",
    "mnist_data = tfds.as_numpy(mnist_data)\n",
    "train_data, test_data = mnist_data['train'], mnist_data['test']\n",
    "num_labels = info.features['label'].num_classes\n",
    "h, w, c = info.features['image'].shape\n",
    "num_pixels = h * w * c\n",
    "\n",
    "# Full train set\n",
    "train_images, train_labels = train_data['image'], train_data['label']\n",
    "train_images = jnp.reshape(train_images, (len(train_images), num_pixels))\n",
    "train_labels = one_hot(train_labels, num_labels)\n",
    "\n",
    "# Full test set\n",
    "test_images, test_labels = test_data['image'], test_data['label']\n",
    "test_images = jnp.reshape(test_images, (len(test_images), num_pixels))\n",
    "test_labels = one_hot(test_labels, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57f46be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     14\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[43mget_train_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     16\u001b[0m         x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mreshape(x, (\u001b[38;5;28mlen\u001b[39m(x), num_pixels))\n\u001b[1;32m     17\u001b[0m         y \u001b[38;5;241m=\u001b[39m one_hot(y, num_labels)\n",
      "Cell \u001b[0;32mIn [1], line 7\u001b[0m, in \u001b[0;36mget_train_batches\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_train_batches\u001b[39m():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# as_supervised=True gives us the (image, label) as a tuple instead of a dict\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     ds \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, as_supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_dir\u001b[38;5;241m=\u001b[39m\u001b[43mdata_dir\u001b[49m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# You can build up an arbitrary tf.data input pipeline\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mbatch(batch_size)\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "def get_train_batches():\n",
    "    # as_supervised=True gives us the (image, label) as a tuple instead of a dict\n",
    "    ds = tfds.load(name='mnist', split='train', as_supervised=True, data_dir=data_dir)\n",
    "    # You can build up an arbitrary tf.data input pipeline\n",
    "    ds = ds.batch(batch_size).prefetch(1)\n",
    "    # tfds.dataset_as_numpy converts the tf.data.Dataset into an iterable of NumPy arrays\n",
    "    return tfds.as_numpy(ds)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for x, y in get_train_batches():\n",
    "        x = jnp.reshape(x, (len(x), num_pixels))\n",
    "        y = one_hot(y, num_labels)\n",
    "        params = update(params, x, y)\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    train_acc = accuracy(params, train_images, train_labels)\n",
    "    test_acc = accuracy(params, test_images, test_labels)\n",
    "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "    print(\"Training set accuracy {}\".format(train_acc))\n",
    "    print(\"Test set accuracy {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b72bd",
   "metadata": {},
   "source": [
    "# 4. Jax - The Sharp Bits\n",
    "\n",
    "https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/Common_Gotchas_in_JAX.ipynb#scrollTo=cDpQ5u63Ba_H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf8240",
   "metadata": {},
   "source": [
    "Some under-the-hood tidbits about jax that are good to know as you can not just rely on errors. JAX is made to operate just like numpy other than the extra transformations. But JAX's approach causes it to deviate sometimes, this can cause issues if not addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e8e94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jax import grad, jit\n",
    "from jax import lax\n",
    "from jax import random\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e8cde",
   "metadata": {},
   "source": [
    "**1. JAX's functional approach**\n",
    "\n",
    "JAX's jit optimizes compilation but expects the functions to be pure. A functionally pure function does not depend on a global state and gives the same output every time for the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e64b69e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing function\n",
      "First call:  4.0\n",
      "Second call:  5.0\n",
      "Executing function\n",
      "Third call, different type:  [5.]\n"
     ]
    }
   ],
   "source": [
    "def impure_print_side_effect(x):\n",
    "    print(\"Executing function\")  # This is a side-effect\n",
    "    return x\n",
    "\n",
    "# The side-effects appear during the first run\n",
    "print (\"First call: \", jit(impure_print_side_effect)(4.))\n",
    "\n",
    "# Subsequent runs with parameters of same type and shape may not show the side-effect\n",
    "# This is because JAX now invokes a cached compilation of the function\n",
    "print (\"Second call: \", jit(impure_print_side_effect)(5.))\n",
    "\n",
    "# JAX re-runs the Python function when the type or shape of the argument changes\n",
    "print (\"Third call, different type: \", jit(impure_print_side_effect)(jnp.array([5.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24fff3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call:  4.0\n",
      "Second call:  5.0\n",
      "Third call, different type:  [14.]\n"
     ]
    }
   ],
   "source": [
    "g = 0.\n",
    "def impure_uses_globals(x):\n",
    "    return x + g\n",
    "\n",
    "# JAX captures the value of the global during the first run\n",
    "print (\"First call: \", jit(impure_uses_globals)(4.))\n",
    "g = 10.  # Update the global\n",
    "\n",
    "# Subsequent runs may silently use the cached value of the globals\n",
    "print (\"Second call: \", jit(impure_uses_globals)(5.))\n",
    "\n",
    "# JAX re-runs the Python function when the type or shape of the argument changes\n",
    "# This will end up reading the latest value of the global\n",
    "print (\"Third call, different type: \", jit(impure_uses_globals)(jnp.array([4.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "727ebebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call:  4.0\n",
      "Saved global:  Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n"
     ]
    }
   ],
   "source": [
    "g = 0.\n",
    "def impure_saves_global(x):\n",
    "    global g\n",
    "    g = x\n",
    "    return x\n",
    "\n",
    "# JAX runs once the transformed function with special Traced values for arguments\n",
    "print (\"First call: \", jit(impure_saves_global)(4.))\n",
    "print (\"Saved global: \", g)  # Saved global has an internal JAX value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e998b",
   "metadata": {},
   "source": [
    "**NOTE**: A Python function can be functionally pure even if it actually uses stateful objects internally, as long as it does not read or write external state. So its fine to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef3c3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "def pure_uses_internal_state(x):\n",
    "    state = dict(even=0, odd=0)\n",
    "    for i in range(10):\n",
    "        state['even' if i % 2 == 0 else 'odd'] += x\n",
    "    return state['even'] + state['odd']\n",
    "\n",
    "print(jit(pure_uses_internal_state)(5.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce475f",
   "metadata": {},
   "source": [
    "It is not recommended to use iterators in any JAX function you want to `jit` or in any control-flow primitive. The reason is that an iterator is a python object which introduces state to retrieve the next element. Therefore, it is incompatible with JAX functional programming model. In the code below, there are some examples of incorrect attempts to use iterators with JAX. Most of them return an error, but some give unexpected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68fb6f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.lax as lax\n",
    "from jax import make_jaxpr\n",
    "\n",
    "# lax.fori_loop\n",
    "array = jnp.arange(10)\n",
    "print(lax.fori_loop(0, 10, lambda i,x: x+array[i], 0)) # expected result 45\n",
    "iterator = iter(range(10))\n",
    "print(lax.fori_loop(0, 10, lambda i,x: x+next(iterator), 0)) # unexpected result 0\n",
    "\n",
    "# lax.scan\n",
    "def func11(arr, extra):\n",
    "    ones = jnp.ones(arr.shape)\n",
    "    def body(carry, aelems):\n",
    "        ae1, ae2 = aelems\n",
    "        return (carry + ae1 * ae2 + extra, carry)\n",
    "    return lax.scan(body, 0., (arr, ones))\n",
    "make_jaxpr(func11)(jnp.arange(16), 5.)\n",
    "# make_jaxpr(func11)(iter(range(16)), 5.) # throws error\n",
    "\n",
    "# lax.cond\n",
    "array_operand = jnp.array([0.])\n",
    "lax.cond(True, lambda x: x+1, lambda x: x-1, array_operand)\n",
    "iter_operand = iter(range(10))\n",
    "# lax.cond(True, lambda x: next(x)+1, lambda x: next(x)-1, iter_operand) # throws error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84451068",
   "metadata": {},
   "source": [
    "**2. JAX's immutability**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8121cb",
   "metadata": {},
   "source": [
    "In numpy we can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02a98037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original array:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "updated array:\n",
      "[[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = np.zeros((3,3), dtype=np.float32)\n",
    "print(\"original array:\")\n",
    "print(numpy_array)\n",
    "\n",
    "# In place, mutating update\n",
    "numpy_array[1, :] = 1.0\n",
    "print(\"updated array:\")\n",
    "print(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ec45d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Minimal\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<class 'jaxlib.xla_extension.DeviceArray'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31mTypeError\u001b[0m\u001b[0;31m:\u001b[0m '<class 'jaxlib.xla_extension.DeviceArray'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\n"
     ]
    }
   ],
   "source": [
    "%xmode Minimal\n",
    "jax_array = jnp.zeros((3,3), dtype=jnp.float32)\n",
    "\n",
    "# In place update of JAX's array will yield an error!\n",
    "jax_array[1, :] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a78f0",
   "metadata": {},
   "source": [
    "JAX not allowing mutability is to avoid issues with its functional approach. Array updates in JAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65349e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated array:\n",
      " [[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "updated_array = jax_array.at[1, :].set(1.0)\n",
    "print(\"updated array:\\n\", updated_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd75255",
   "metadata": {},
   "source": [
    "**NOTE:** JAX's updating is out-of-place to preserve functional-ness. New array, new pointer. But it does optimize and update in-place in a `jit` context to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97a0c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original array unchanged:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"original array unchanged:\\n\", jax_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43bf52",
   "metadata": {},
   "source": [
    "Index-based operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a52c826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original array:\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n",
      "new array post-addition:\n",
      "[[1. 1. 1. 8. 8. 8.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 8. 8. 8.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 8. 8. 8.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"original array:\")\n",
    "jax_array = jnp.ones((5, 6))\n",
    "print(jax_array)\n",
    "\n",
    "new_jax_array = jax_array.at[::2, 3:].add(7.)\n",
    "print(\"new array post-addition:\")\n",
    "print(new_jax_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377cb590",
   "metadata": {},
   "source": [
    "Another issue with JAX's approach  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
